{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: Assignment - Comparison Exercise - Analyzing Deep Learning Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we will try using both TensorFlow and PyTorch to train a model on a bird species dataset.  We will look at runtime information as well as CPU/GPU/Memory load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.6.6)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.66.2)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.2.1)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (3.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and extracted to: birds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Download the bird identification dataset from Kaggle https://www.kaggle.com/datasets/gpiosenka/100-bird-species\n",
    "dataset_name = 'gpiosenka/100-bird-species'\n",
    "path_to_download = 'birds'  # Specify your download path here\n",
    "\n",
    "api.dataset_download_files(dataset_name, path=path_to_download, unzip=True)\n",
    "\n",
    "print(f'Dataset downloaded and extracted to: {path_to_download}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with the Kaggle 525 Bird Species dataset using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84635 files belonging to 525 classes.\n",
      "Found 2625 files belonging to 525 classes.\n",
      "Found 2625 files belonging to 525 classes.\n",
      "['train/ABBOTTS BABBLER/001.jpg' 'train/ABBOTTS BABBLER/007.jpg'\n",
      " 'train/ABBOTTS BABBLER/008.jpg' ... 'valid/BLACK BREASTED PUFFBIRD/1.jpg'\n",
      " 'valid/BLACK BREASTED PUFFBIRD/2.jpg'\n",
      " 'valid/BLACK BREASTED PUFFBIRD/5.jpg']\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n",
      "Epoch 1/5\n",
      "2645/2645 [==============================] - 114s 43ms/step - loss: 4.8513 - accuracy: 0.0920 - val_loss: 3.9194 - val_accuracy: 0.1817\n",
      "Epoch 2/5\n",
      "2645/2645 [==============================] - 114s 43ms/step - loss: 3.6780 - accuracy: 0.2159 - val_loss: 3.7561 - val_accuracy: 0.2091\n",
      "Epoch 3/5\n",
      "2645/2645 [==============================] - 114s 43ms/step - loss: 2.9569 - accuracy: 0.3253 - val_loss: 4.0514 - val_accuracy: 0.2046\n",
      "Epoch 4/5\n",
      "2645/2645 [==============================] - 115s 44ms/step - loss: 2.2762 - accuracy: 0.4478 - val_loss: 4.3868 - val_accuracy: 0.2038\n",
      "Epoch 5/5\n",
      "2645/2645 [==============================] - 114s 43ms/step - loss: 1.7242 - accuracy: 0.5636 - val_loss: 5.3136 - val_accuracy: 0.1764\n",
      "83/83 [==============================] - 3s 36ms/step - loss: 5.1356 - accuracy: 0.1829\n",
      "83/83 [==============================] - 2s 26ms/step\n",
      "[[4.1532512e-06 1.2872862e-06 2.6564427e-05 ... 1.7505955e-21\n",
      "  4.3980407e-22 3.5795259e-22]\n",
      " [5.8986415e-04 4.8829963e-07 2.5320674e-05 ... 7.2170877e-30\n",
      "  5.1466340e-31 1.8402985e-30]\n",
      " [1.9178277e-25 5.7101464e-28 1.0762501e-12 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [1.6687823e-14 8.6470375e-14 1.6596321e-09 ... 1.4757112e-34\n",
      "  7.2940752e-36 1.1367316e-35]\n",
      " [2.6255438e-09 3.5707751e-06 2.2162918e-05 ... 2.4520999e-26\n",
      "  7.6373609e-28 8.7564824e-27]\n",
      " [2.3948163e-08 8.6802165e-06 7.0558337e-10 ... 6.1010442e-28\n",
      "  4.9018564e-29 2.1732543e-28]]\n",
      "The code execution took 11 minutes and 5.596363721000671 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Import Tensor Flow\n",
    "import tensorflow\n",
    "# Import Keras\n",
    "from tensorflow import keras\n",
    "# Import Numpy\n",
    "import numpy as np\n",
    "# Import time for measuring the time taken to build the model\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# import the dataset\n",
    "train_data = keras.utils.image_dataset_from_directory('birds/train', image_size=(224, 224), batch_size=32)\n",
    "test_data = keras.utils.image_dataset_from_directory('birds/test', image_size=(224, 224), batch_size=32)\n",
    "validation_data = keras.utils.image_dataset_from_directory('birds/valid', image_size=(224, 224), batch_size=32)\n",
    "# Load the class names from csv file\n",
    "class_names = np.loadtxt('birds/birds.csv', delimiter=',', usecols=(1,), dtype=str, skiprows=1)\n",
    "# Print the class names\n",
    "print(class_names)\n",
    "# Print the shape of the training data\n",
    "print(train_data)\n",
    "# Print the shape of the test data\n",
    "print(test_data)\n",
    "# Print the shape of the validation data\n",
    "print(validation_data)\n",
    "\n",
    "\n",
    "# Example of normalization for image data\n",
    "train_data = train_data.map(lambda x, y: (x / 255.0, y))\n",
    "test_data = test_data.map(lambda x, y: (x / 255.0, y))\n",
    "validation_data = validation_data.map(lambda x, y: (x / 255.0, y))\n",
    "\n",
    "# Create a CNN model\n",
    "tf_model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "tf_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "tf_model.fit(train_data, epochs=5, validation_data=validation_data)\n",
    "\n",
    "# Evaluate the model\n",
    "tf_model.evaluate(test_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = tf_model.predict(test_data)\n",
    "# Print the predictionsf\n",
    "print(predictions)\n",
    "\n",
    "stop_time = time.perf_counter()\n",
    "duration_seconds = stop_time - start_time\n",
    "\n",
    "# Convert seconds to minutes and seconds for easier reading\n",
    "minutes = duration_seconds // 60\n",
    "seconds = duration_seconds % 60\n",
    "\n",
    "print(f\"The code execution took {int(minutes)} minutes and {seconds} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code execution took 11 minutes and 5.596363721000671 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with the 525 Bird Species dataset using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n",
      "['train/ABBOTTS BABBLER/001.jpg' 'train/ABBOTTS BABBLER/007.jpg'\n",
      " 'train/ABBOTTS BABBLER/008.jpg' ... 'valid/BLACK BREASTED PUFFBIRD/1.jpg'\n",
      " 'valid/BLACK BREASTED PUFFBIRD/2.jpg'\n",
      " 'valid/BLACK BREASTED PUFFBIRD/5.jpg']\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 84635\n",
      "    Root location: birds/train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 2625\n",
      "    Root location: birds/test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 2625\n",
      "    Root location: birds/valid\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "           )\n",
      "Temporary Model Shape torch.Size([32, 394272])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 4.6577:   0%|          | 0/2645 [29:31<?, ?it/s]  \n",
      "Epoch 2/5, Loss: 4.1207:   0%|          | 0/2645 [28:33<?, ?it/s]\n",
      "Epoch 3/5, Loss: 2.6836:   0%|          | 0/2645 [27:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 83\u001b[0m\n\u001b[1;32m     81\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     82\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 83\u001b[0m         progress_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     86\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using:\", device)\n",
    "\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder('birds/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder('birds/test', transform=transform)\n",
    "validation_dataset = datasets.ImageFolder('birds/valid', transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load the class names from csv file\n",
    "class_names = np.loadtxt('birds/birds.csv', delimiter=',', usecols=(1,), dtype=str, skiprows=1)\n",
    "# Print the class names\n",
    "print(class_names)\n",
    "# Print the shape of the training data\n",
    "print(train_dataset)\n",
    "# Print the shape of the test data\n",
    "print(test_dataset)\n",
    "# Print the shape of the validation data\n",
    "print(validation_dataset)\n",
    "\n",
    "\n",
    "# Creating a temporary model to determine input size for first linear layer\n",
    "temp_model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 32, 3, 1),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten()\n",
    ")\n",
    "\n",
    "x, _ = next(iter(train_loader))\n",
    "x = temp_model(x)\n",
    "print('Temporary Model Shape',x.shape)\n",
    "\n",
    "\n",
    "# Create a CNN model with PyTorch\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 32, 3, 1),\n",
    "    torch.nn.MaxPool2d(2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(394272, 128),\n",
    "    torch.nn.Linear(128, len(class_names))\n",
    ")\n",
    "\n",
    "# move the model to the GPU\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(5):\n",
    "    progress_bar = tqdm.tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.set_description(f'Epoch {epoch + 1}/{5}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    progress_bar = tqdm.tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        progress_bar.set_description(f'Accuracy: {correct / total}')\n",
    "\n",
    "print(f'Accuracy: {correct / total}')\n",
    "\n",
    "\n",
    "# Timing the model building\n",
    "stop_time = time.perf_counter()\n",
    "duration_seconds = stop_time - start_time\n",
    "\n",
    "# Convert seconds to minutes and seconds for easier reading\n",
    "minutes = duration_seconds // 60\n",
    "seconds = duration_seconds % 60\n",
    "\n",
    "print(f\"The code execution took {int(minutes)} minutes and {seconds} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "From here we see that the TensorFlow option ran quicker.  The loss ration for the PyTorch option is lower though.  These loss ratios could be improved with more work eithe preprocessing the data, or by looking at changing the way the model is built, possibly adding some dropout to reduce overfitting.\n",
    "\n",
    "CPU utilization was fairly low on both methods since a GPU was available, and the GPU utilization was near 100% the duration of the training.  Memroy utilization seemed to be slightly lower using PyTorch, but the difference was too small to be sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Reflection\n",
    "\n",
    "The speed of TensorFlow makes it the better choice in this situation.  Also the integration of Keras into TensorFlow 2.0 makes it much more intuiative when dealing with loading datasets and preparing the data for training.  The difference in loss ratio between the two frameworks does not justify the time expendeture in my opinion and I believe moving forward I will tend to use TensorFlow more often, unless there is a specific reason to use PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
